---
format: 
  revealjs:
    transition-speed: fast
    slide-number: c/t
    css: custom.css
    transition: fade
    incremental: false 
    theme: default
    footer: "Slides URL: <https://ecssc2024.patrickli.org>"
    logo: figures/monash-stacked-blue-rgb.png
    embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE
)

library(tidyverse)
library(glue)
```

## autovi: Automated Assessment of Residual Plots Using Computer Vision {.center style="text-align: right;"}

::: {style="color: #5A5A5A"}

ECSSC2024

:::


#### Weihao (Patrick) Li {style="margin-top: 40px; font-size: 0.9em"}

::: {style="font-size: 0.9em"}

Monash University

:::

---

## ‚úçÔ∏èCo-authors {visibility="hidden"}

::: {.columns style="font-size:50%"}

::: {.column width="25%"}

![](figures/dicook.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Professor Dianne Cook, Department of Econometrics and Business Statistics, Melbourne, Monash University, Australia

:::

::: {.column width="25%"}

![](figures/emitanaka.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Dr. Emi Tanaka, Biological Data Science Institute, Australian National University, Canberra, Australia

:::


::: {.column width="25%"}

![](figures/susan.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Assistant Professor Susan VanderPlas, Statistics Department, University of Nebraska, Lincoln, USA

:::

::: {.column width="25%"}

![](figures/klaus.jpeg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Senior Lecturer Klaus Ackermann, Department of Econometrics and Business Statistics, Melbourne, Monash University, Australia

:::

:::

---

## ü§îChallenges

:::: {.columns}

::: {.column width="40%"}

```{r fig.width=5, fig.height=5, fig.retina=3, warning=FALSE, message=FALSE}
library(tidyverse)
library(visage)
set.seed(452)
ori_x <- rand_lognormal()
mod <- heter_model(b = 0, x = closed_form(~-ori_x))
ori_dat <- mod$gen(300)

ori_dat %>%
  VI_MODEL$plot(theme = theme_light(base_size = 18), size = 1, remove_grid_line = TRUE, ) +
  # geom_line(aes(x = .fitted, y = (3.5 + 0.3 * .fitted)), col = "red") +
  # geom_line(aes(x = .fitted, y = -(3.5 + 0.3 * .fitted)), col = "red") +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::


::: {.column width="60%"}

- Vertical spread of the points varies with the fitted values indicates **the existence of heteroskedasticity**.

- However, this is an **over-interpretation**.

- The visual pattern is caused by a **skewed distribution of the predictor**.



:::

::::


---

## üé≤Residual Distribution {visibility="hidden"}

Consider the **classical normal linear regression model**

$$\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}, \quad \boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n, \sigma^2\boldsymbol{I}_n).$$

By the **Frisch-Waugh-Lowell theorem**,

$$\boldsymbol{e} = \boldsymbol{R}\boldsymbol{\varepsilon},$$
where $\boldsymbol{R}=\boldsymbol{I}_n -\boldsymbol{X}(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'$.

We treat $\boldsymbol{e}$ as **a vector of random variables** here.

---


## üé≤Residual Distribution {visibility="hidden"}

For a **correctly specified model**, $$\boldsymbol{e} \sim N(\boldsymbol{0}_n, \text{diag}(\boldsymbol{R}\sigma^2)).$$ 

For simplicity, we will replace $\text{cov}(\boldsymbol{e}, \boldsymbol{e}) = \boldsymbol{R}\boldsymbol{R}'\sigma^2 = \boldsymbol{R}\sigma^2$ with a **full-rank diagonal matrix** $\text{diag}(\boldsymbol{R}\sigma^2)$.

Symbol $Q$ will be used to represent this **reference residual distribution**. 



---

## üé≤Residual Distribution {visibility="hidden"}

::: {style="font-size:80%"}

However, if the model is **misspecified**, then the **actual residual distribution** denoted as $P$, will be **different** from $Q$.

- If $\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n,\boldsymbol{V})$, where $\boldsymbol{V} \neq \sigma^2\boldsymbol{I}_n$,  $$\boldsymbol{e} \sim N(\boldsymbol{0}_n, \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R})) \implies \text{Heteroskedasticity}.$$

- And if some necessary higher-order predictors $\boldsymbol{Z}$ are also omitted, $$\boldsymbol{e} \sim N(\boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z, \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R})) \implies \text{Non-linearity}~ \& ~\text{Heteroskedasticity}.$$

:::

---

## üìèKL Divergence of $P$ from $Q$ {visibility="hidden"}

::: {style="font-size:80%"}

We defined a **distance measure** based on **Kullback-Leibler divergence** to quantify the **extent of model violations**

\begin{align}
\label{eq:kl-0}
D &= \log\left(1 + \int_{\mathbb{R}^{n}}\log\frac{p(\boldsymbol{e})}{q(\boldsymbol{e})}p(\boldsymbol{e})d\boldsymbol{e}\right), \\
\end{align}

- $P$: **reference residual distribution** assumed under correct model specification.
- $Q$: **actual residual distribution**.

- $D = 0$ if and only if $P \equiv Q$.
- However, $Q$ is typically unknown $\Rightarrow$ $D$ can not be computed.

:::


---

## üéØEstimation of the Distance {visibility="hidden"}

::: {.fragment}

We can train a **computer vision model** to estimate $D$ with **a residual plot**

\begin{equation}
\label{eq:d-approx}
\widehat{D} = f_{CV}(V_{h \times w}(\boldsymbol{e}, \boldsymbol{\hat{y}})),
\end{equation}

where $V_{h \times w}(.)$ is a **plotting function** that saves a residual plot as an image with $h \times w$ pixels, and  $f_{CV}(.)$ is a **computer vision model** which predicts distance in $[0, +\infty)$.

:::

---

## üî¨Statistical Testing {visibility="hidden"}

The **null distribution** can be estimated by predicting $\widehat{D}$ for **a large number of null plots**. 

- The **$p$-value** is the proportion of null plots having estimated distance **greater than or equal to** the observed one.



---

## üí°Non-linearity {visibility="hidden"}


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=10, fig.height=4}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, include_x2 = FALSE, sigma = 0.05)$gen(500) %>%
  mutate(j = 2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(3:11, function(j) {
  phn_model(j = j, include_x2 = FALSE, sigma = 0.05)$
    gen(500, computed = select(dat_shape_1, x1, e)) %>%
  mutate(j = j)
}) %>%
  
# Combined with data for shape 1
bind_rows(dat_shape_1) %>%
  mutate(j = factor(j)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~j, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=8, fig.height=2}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, include_x2 = FALSE, sigma = 0.05)$gen(500) %>%
  mutate(e_sigma = 0.2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(c(0.4, 0.8, 1.6, 3.2), function(e_sigma) {
  phn_model(j = 2, include_x2 = FALSE, sigma = e_sigma)$
    gen(500, computed = select(dat_shape_1, x1, e) %>% mutate(e = e/0.2*e_sigma)) %>%
  mutate(e_sigma = e_sigma)
}) %>%
  
# Combined with data for shape 1
bind_rows(dat_shape_1) %>%
  mutate(e_sigma = factor(e_sigma)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~e_sigma, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::

---


## üí°Heteroskedasticity {visibility="hidden"}



:::: {.columns}

::: {.column width="70%"}

```{r fig.width=10, fig.height=4}
set.seed(10085)

# Generate data for a = -1
dat_a_n1 <- phn_model(include_z = FALSE,
                      include_x2 = FALSE,
                      a = -1,
                      b = 100)$gen(500) %>%
  mutate(a = -1)

# Generate data for other a
map(c(-0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1), function(a) {
  phn_model(include_z = FALSE,
            include_x2 = FALSE,
            a = a,
            b = 100)$gen(500) %>%
  mutate(a = a)
}) %>%
  
  # Combined with data for a = -1
  bind_rows(dat_a_n1) %>%
  mutate(a = factor(a)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~a, scales = "free", ncol = 5) +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::

:::


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=8, fig.height=2}
set.seed(10085)

# Generate data for a = -1
dat_a_n1 <- phn_model(include_z = FALSE,
                      include_x2 = FALSE,
                      a = -1,
                      b = 6)$gen(500) %>%
  mutate(b = 6)

# Generate data for other a
map(c(3, 1.5, 1, 0.5), function(b) {
  phn_model(include_z = FALSE,
            include_x2 = FALSE,
            a = -1,
            b = b)$gen(500) %>%
  mutate(b = b)
}) %>%
  
  # Combined with data for a = -1
  bind_rows(dat_a_n1) %>%
  mutate(b = factor(b)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~b, scales = "free", ncol = 5) +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::

:::

---

## üí°Non-normality {visibility="hidden"}



:::: {.columns}

::: {.column width="30%"}


**Distribution of $\varepsilon$**

:::

::: {.column width="70%"}

```{r fig.width=8, fig.height=6}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_uniform(-1.4, 1.4))$gen(500) %>%
  mutate(e_dist = "uniform")

dat_shape_2 <- phn_model(include_z = FALSE, include_x2 = FALSE, sigma = 0.8)$gen(500) %>%
  mutate(e_dist = "normal")

dat_shape_3 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_lognormal(sigma = 0.6))$gen(500) %>%
  mutate(e_dist = "lognormal")

dat_shape_4 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_uniform_d(-1.4, 1.4, even = TRUE))$gen(500) %>%
  mutate(e_dist = "discrete")

# Generate data for shape 2, 3 and 4. Reuse x and e.
bind_rows(dat_shape_1, dat_shape_2, dat_shape_3, dat_shape_4) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~e_dist, scales = "free", labeller = label_parsed, ncol = 2)
```

:::

:::


---

## `r fontawesome::fa_i("r-project")` `autovi` Package

::: {style="font-size:80%"}

The `autovi` package provides automated assessment of residual plot with **computer vision models**. 

It estimates **visual signal strength (VSS)**, which is the KL divergence between a residual plot and a reference **null residual plot**.

#### Core Methods

- Null residuals simulation: `rotate_resid()`
- Visual signal strength: `vss()`
- Comprehensive checks: `check()` and `summary_plot()`

:::

---

## üí°Example: Boston Housing

::: {style="font-size:80%"}

```{r}
housing <- read_csv(here::here("data/housing.csv"))
```


```{r}
#| echo: true
#| fig-height: 4
#| fig-width: 6
fitted_model <- lm(MEDV ~ RM + LSTAT + PTRATIO, data = housing)
ggplot() +
  geom_point(aes(fitted(fitted_model), 
                 resid(fitted_model))) +
  theme_void()
```

:::

```{r}
#| echo: false
#| message: false
#| fig-height: 4
#| fig-width: 6
library(autovi)
checker <- auto_vi(fitted_model = fitted_model, 
                   keras_model = get_keras_model("vss_phn_32"))
checker$check_result <- readRDS(here::here("data/check_result_1.rds"))
```

---

## `r fontawesome::fa_i("r-project")` `rotate_resid()`

::: {style="font-size:80%"}

Null residuals are simulated from the fitted model assuming it is **correctly specified**.

::: {.columns}

::: {.column width="50%"}

```{.r}
checker <- residual_checker(fitted_model)
checker$rotate_resid()
```

```{r}
#| echo: false
#| message: false
checker$rotate_resid()
```

:::

::: {.column width="50%"}

```{.r}
checker$rotate_resid() |>
  checker$plot_resid()
```


```{r}
#| echo: false
#| message: false
#| fig-height: 4
#| fig-width: 6
checker$rotate_resid() |>
  checker$plot_resid()
```

:::

:::

:::

---

## `r fontawesome::fa_i("r-project")` `vss()`


::: {style="font-size:80%"}

::: {.columns}

::: {.column width="50%"}

#### Visual signal strength of the actual residual plot

```{.r}
checker$vss()
```

```{r}
#| echo: false
#| message: true
checker$vss()
```

:::

::: {.column width="50%"}

#### Visual signal strength of a null plot

```{.r}
checker$rotate_resid() |>
  checker$vss()
```


```{r}
#| echo: false
#| message: true
checker$rotate_resid() |>
  checker$vss()
```


:::

:::

:::

---

## `r fontawesome::fa_i("r-project")` `check()`

```{.r}
checker$check()
```

```{r}
#| echo: false
#| message: true
checker
```

---

## `r fontawesome::fa_i("r-project")` `summary_plot()`

```{r}
#| echo: true
checker$summary_plot()
```


---

## üí°Example: Left-triangle

::: {style="font-size:70%"}

Breusch‚ÄìPagan test $p$-value = 0.0457

```{r fig.height=4, fig.width=6}
set.seed(452)
ori_x <- rand_lognormal()
dat <- heter_model(b = 0, x = closed_form(~-ori_x))$gen(300)

mod <- lm(y ~ x, data = dat)
my_vi <- autovi::auto_vi(fitted_model = mod)
my_vi$plot_resid() -> p1
```

```{r dpi=300}
my_vi$check_result <- readRDS(here::here("data/fig1_check.rds"))
my_vi$summary_plot() +
  theme(legend.position = "bottom", legend.box="vertical") +
  labs(linetype = "") -> p2

patchwork::wrap_plots(p1, p2, ncol = 2)
```

:::

---

## üí°Example: Dinosaur

::: {style="font-size:70%"}

::: {.columns}

::: {.column width="50%"}

Ramsey Regression Equation Specification Error test $p$-value = 0.742

Breusch‚ÄìPagan test $p$-value = 0.36

Shapiro-Wilk test $p$-value = 9.21e-05

```{r fig.height=4, fig.width=6, dpi=300}
dino <- datasauRus::datasaurus_dozen %>% filter(dataset == "dino")
mod <- lm(y ~ ., data = select(dino, -dataset))

my_vi <- autovi::auto_vi(fitted_model = mod)
my_vi$plot_resid()
```

:::

::: {.column width="50%"}

```{r fig.height=4.5, fig.width=4.5, dpi=300}
my_vi$check_result <- readRDS(here::here("data/dino_check.rds"))
my_vi$summary_plot() +
  theme(legend.position = "bottom", legend.box="vertical") +
  labs(linetype = "")
```

:::

:::

:::

---

## üß™Compared to Visual Tests {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/human-mosaic-1.pdf", pages = 1)
```

---

## üß™Compared to RESET and BP Tests {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/conv-mosaic-1.pdf", pages = 1)
```

---

## üß™Power Comparison {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/fig-power-1.pdf", pages = 1)
```

---

## üåêShiny Application {.center}

Don't want to install `TensorFlow`? 

Try our shiny web application: <https://autoviweb.patrickli.org>

---


## Thanks! Any questions? {.center}

<br>

### üîóRelevant links

::: {.nonincremental}

`r fontawesome::fa_i("github")` tengmcing

`r fontawesome::fa_i("envelope")` patrick.li@monash.edu

üì¶ [`autovi`](https://github.com/TengMCing/autovi){target="_blank"}

üìú [Slides](https://github.com/TengMCing/ecssc2024){target="_blank"}


:::


